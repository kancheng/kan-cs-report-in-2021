# CV Homework

> PKU 信息工程學院 2101212850 干皓丞

## 0. About

此作業以 LaTeX 版本為主，詳見專案目錄下的 report.pdf，並使用騰訊文檔進行 Demo。而程式碼則詳見專案目錄 code 下的 mnist-init-release.ipynb 和 mnist-tensorflow.ipynb 。

> 這回作業主要是提升 PyTorch MNIS 的範例程式碼性能為主，但是過程中發現不少重要的知識點，包含不同平臺的程式碼與思路與歷年的研究，在此先作紀錄，留待後續可以做出有更好的成果。

### Tasks

改進程式碼

![](https://github.com/kancheng/kan-cs-report-in-2021/blob/main/CV/pytorch-tensorflow-mnist/pic/1.png)

### PyTorch MNIST Traing

其來源為課堂的 Demo，程式碼則詳見專案目錄 code 下的  mnist-init-release.ipynb，而原始程式碼則為專案目錄 code 下的  W6_MNIST_FC.ipynb。

### TensorFlow MNIST Traing

其來源為 Google 官方 Demo 的 Code，程式碼則詳見專案目錄 code 下的  mnist-tensorflow.ipynb 。


### CNN 文獻

 - Y. Lecun et al., Gradient-based learning applied to document recognition, LeNet, 1998.
 - Alex Krizhevsky et al., ImageNet Classification with Deep Convolutional Neural Networks, AlexNet, 2012.
 - Karen Simonyan et al., Very Deep Convolutional Networks for Large-Scale Image Recognition, VGG, 2014.
 - Christian Szegedy et al., Going Deeper with Convolutions, Inception Net, 2014, Google Inc.
 - Sergey Ioffe et al., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, Inception Net V2 , 2015, Google Inc.
 - Christian Szegedy et al., Rethinking the Inception Architecture for Computer Vision, Inception Net V3, 2015, Google Inc.
 - Christian Szegedy et al., Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, Inception Net V4, 2016, Google Inc.
 - François Chollet, Xception: Deep Learning with Depthwise Separable Convolutions, Xception, 2016, Google Inc.
 - Kaiming He et al., Deep Residual Learning for Image Recognition, ResNet, 2015, Microsoft Research
 - Gao Huang et al., Densely Connected Convolutional Networks, DenseNet, 2016
 - Andrew G. Howard et al., MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, MobileNet V1, 2017, Google Inc.
 - Mark Sandler et al., MobileNetV2: Inverted Residuals and Linear Bottlenecks, MobileNet V2, 2018, Google Inc.
 - Andrew Howard et al., Searching for MobileNetV3, MobileNet V3, 2019, Google AI and Google Brain.
 - Xiangyu Zhang et al., ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, ShuffleNet V1, 2017. 
 - Xiangyu Zhang et al., ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design, ShuffleNet V2, 2018.

### Reference

>
>  順帶研究如下 ：
>   1) Pytorch & MNIST 訓練
>   2) TensorFlow & MNIST 訓練
>   3) CNN 歷年來的研究發展
>   涵蓋解決的過程連結。
>

1. https://nextjournal.com/gkoehler/pytorch-mnist

2. https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist

3. https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118

4. https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/

5. https://www.tensorflow.org/tutorials/images/cnn

6. https://www.tensorflow.org/datasets/keras_example

7. https://zhuanlan.zhihu.com/p/76275427

8. https://zhuanlan.zhihu.com/p/39068853

9. https://www.reddit.com/r/MachineLearning/comments/cikcr3/d_shufflenet_v2_on_mnist_dataset/

10. https://github.com/allen108108/Model-Optimizer_Implementation

11. https://www.jiqizhixin.com/articles/2019-05-27-4

12. https://pytorch.org/hub/pytorch_vision_shufflenet_v2/

13. https://blog.csdn.net/EasonCcc/article/details/109001050

14. https://arxiv.org/abs/1807.11164

15. https://github.com/ZhuYun97/ShuffleNet-v2-Pytorch

16. https://www.jiqizhixin.com/articles/2019-06-03-14

17. https://www.zhihu.com/question/32673260

18. https://blog.csdn.net/JueChenYi/article/details/77116011

19. https://www.plob.org/article/13244.html

20. https://www.jiqizhixin.com/articles/2018-07-12-4

21. https://towardsdatascience.com/the-brief-history-of-convolutional-neural-networks-45afa1046f7f



