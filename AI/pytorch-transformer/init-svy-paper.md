# About

0. Transformers in Vision: A Survey

1. Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks

2. Deep amortized clustering

3. Non-local Neural Networks

4. Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation

5. Taming Transformers for High-Resolution Image Synthesis

6. Video Action Transformer Network


# Transformers in Vision: A Survey

Transformer 模型在自然语言任务上的惊人结果引起了视觉界的兴趣，研究它们在计算机视觉问题中的应用，Transformer 与类似如长短期记忆 (LSTM)等的循环网络相比，Transformers 的显着优势之一是能够对输入序列元素之间的长期依赖关系进行建模，并支持序列的并行处理。 Transformer 与卷积网络不同，Transformer 的设计需要最小的归纳偏差，自然适合作为集合函数。此外 Transformers 的简单设计允许使用类似的处理块处理多种模态（例如，图像、视频、文本和语音），并展示了对超大容量网络和庞大数据集的出色可扩展性。这些优势使使用 Transformer 网络的许多视觉任务取得了令人兴奋的进展。本次调查旨在全面概述计算机视觉学科中的 Transformer 模型。研究者首先介绍 Transformers 成功背后的基本概念，即自我注意、大规模预训练和双向特征编码。然后，我们介绍了转换器在视觉中的广泛应用，包括如图像分类、对象检测、动作识别和分割等流行的识别任务领域，生成建模领域，又如视觉问答、视觉推理和视觉基础等多模态任务，再如活动识别、视频预测的视频处理领域，或者是图像超分辨率、图像增强和着色的 low-level vision 领域和点云分类和分割的 3D 分析。研究者比较了流行技术在架构设计和实验价值方面的各自优势和局限性。最后该研究对开放的研究方向和未来可能的工作进行了分析，此研究希望这项努力将进一步激发社区的兴趣，以解决当前在计算机视觉中应用变压器模型所面临的挑战。

Index Terms—Self-attention, transformers, 双向编码器(bidirectional encoders), deep neural networks, convolutional networks, self-supervision.

https://arxiv.org/abs/2101.01169


# Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks

Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, Yee Whye Teh

https://arxiv.org/abs/1810.00825


# Deep amortized clustering

Juho Lee, Yoonho Lee, Yee Whye Teh

https://arxiv.org/abs/1909.13433


# Non-local Neural Networks

Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He

https://arxiv.org/abs/1711.07971


# Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation

Huiyu Wang, Yukun Zhu, Bradley Green, Hartwig Adam, Alan Yuille, Liang-Chieh Chen

https://arxiv.org/abs/2003.07853


# Taming Transformers for High-Resolution Image Synthesis

Patrick Esser, Robin Rombach, Björn Ommer

https://arxiv.org/abs/2012.09841


# Video Action Transformer Network

Rohit Girdhar, João Carreira, Carl Doersch, Andrew Zisserman

https://arxiv.org/abs/1812.02707


